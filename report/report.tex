% https://www.springer.com/gp/computer-science/lncs/conference-proceedings-guidelines
\documentclass[runningheads]{llncs}
%
\usepackage[T1]{fontenc}
% T1 fonts will be used to generate the final print and online PDFs,
% so please use T1 fonts in your manuscript whenever possible.
% Other font encondings may result in incorrect characters.
%
\usepackage{graphicx}
\usepackage{float}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{parselines}
% Used for displaying a sample figure. If possible, figure files should
% be included in EPS format.
%
% If you use the hyperref package, please uncomment the following two lines
% to display URLs in blue roman font according to Springer's eBook style:
%\usepackage{color}
%\renewcommand\UrlFont{\color{blue}\rmfamily}
%\urlstyle{rm}
%
\begin{document}
%
\title{A System Analysis to Dkron Scheduler}


%
%\titlerunning{Abbreviated paper title}
% If the paper title is too long for the running head, you can set
% an abbreviated paper title here
%
\author{Miguel Albuquerque, 1105828\inst{1}\orcidID{1105828}}
\institute{Instituto Superior TÃ©cnico, Av. Rovisco Pais 1, 1049-001 Lisboa, Portugal
\email{miguel.albuquerque@tecnico.ulisboa.pt}}
%
\maketitle              % typeset the header of the contribution
%
\begin{abstract}
WRITE ABSTRACT HERE
\end{abstract}

\par
\text{Repository: \href{https://github.com/miguel-msa/dkron-study}{github.com/miguel-msa/dkron-study}}
\par
\text{Commit hash:}\textbf{PUT COMMIT HASH HERE}

\keywords{Dkron \and Distributed \and Benchmark \and Scalability \and Consensus \and Dkron Server \ and Dkron Agent .}
%
%
%
% %%%
% %%%
\begin{figure}
\centering
\includegraphics[width=0.25\textwidth]{media/dkron-logo.png}
%\caption{dkron Logo .} \label{fig1}
\end{figure}
\section{Introduction}
TODO: add
- context on what are these systems
- problem it solves
- contextualize dkron into the above
%brief presentation of the selected system and the justification for its choice.
%The report should also specify the git commit identifier, and the url and hash of the video that should be considered for evaluation purposes. Failure to do so will result in a grade penalty.

On the surface, Dkron provides an interface that:
\begin{enumerate}
    \item Has flexible tag-based job definition
    \item Allows for Distributed execution, where these jobs can be ran in a distributed mode. % todo: review this!
    \item Has no Single Point of Failure.
    \item Easy to deploy with built-in replicated storage (BuntDB) relying on the Raft protocol.
    \item Provides a Web-GUI for administration.
\end{enumerate}
The above characteristics, and more, are further explored in \ref{system_description}

\break
When selecting the system to analyse, some of the factors driving the ultimate choice were:
\begin{enumerate}
    \item Interest in exploring \href{https://go.dev/}{Go} source code.
    \item Understand more about a system that is not a database
    \item IS THIS OK? REVIEW THIS
\end{enumerate}
After finding some systems fulfilling these requirements, Dkron became the system that raised a curious question:
\textit{What is the performance of a scheduler, seemingly, focused on availability? and reliability?}

As this is not explored by Dkron, I became interested in finding out the implementation, e.g. scheduling approach, and extrapolate,
joined with benchmarking, its behavior, i.e., its performance, and scaling capacity.

~\\
Ultimately, Dkron is a golang written scheduler with specific particularities for some key use-cases.
Its claims are not bold, neither on its performance, nor on how it actually does scheduling. This opens an
opportunity to not only explore something unclaimed, but also on how Dkron found the
optimal point, if exists, between performance and reliability.

%Some of the claimed use-cases are:
%- Email delivery
%- Payroll generation
%- Bookkeeping
%- Data consolidation for BI
%- Recurring invoicing
%- Data transfer

% TODO
% ! TODO: this text needs to change
% TODO: these claims are NOT CAREFULLY CONSIDERED! REVIEW THIS!!!
~\\ The analysis will consider these use-cases and apply a ...benchmark... to analyse the performance and infer Dkron's
performance on workloads similar, as in trying to represent, to such use-cases.
% TODO: these claims are NOT CAREFULLY CONSIDERED! REVIEW THIS!!!

\section{System Description}
\label{system_description}

PUT HERE ALL THE relevant PERKS\&QUIRKS of Dkron in detail

Always available: Using the power of the Raft protocol, Dkron is designed to be always available. If the cluster leader node fails, a follower will replace it, all without human intervention.

Flexible targets: Simple but powerful tag-based target node selection for jobs. Tag node count allows to run jobs in an arbitrary number of nodes in the same group or groups.

% todo: summarize the dkron relevant doc. sections

\subsection{Getting started}
Dkron has 2 kinds of nodes:
\begin{itemize}
    \item Agent
    \item Server
\end{itemize}
Both are cluster members available to run scheduled jobs
An agent can handle job executions, run scripts and return the resulting output to the server.
A server does everything an Agent does (does it? CHECK better), plus:
\begin{itemize}
    \item schedules the jobs
    \item handles data storage
    \item participate on leader (raft) election
    \item dispatches the execution of jobs either to Agents, or other Servers (CHECK: only other servers???).
\end{itemize}

A Dkron cluster has a leader, for raft based distribution, which is responsible to start job execution queries in the cluster.

By default, all nodes execute each job. This can be controlled through the use of tags and
a count of target nodes having this tag. "This allows to run jobs across a cluster of any size and with any
combination of machines needed."

All execution responses are gathered by the scheduler and stored in the BuntDB storage.

--- SHOW HERE A CODE EXAMPLE OF TAG-BASED JOB SCHEDULE ---

State Storage: BuntDB
The scheduler state is replicated (not throughout, its different, CHECK) between all server nodes using the Serf.

--
Dkron can either run on a single node (by default) or on a cluster with multiple nodes.

CHECK: Create a Job @ https://dkron.io/docs/basics/getting-started more details there might be interesting

\subsection{Intro}
THIS INFO MAY BE TRANSFERRED TO INTRO AND INTRO MAY SUFFER CHANGES!!! REVIEW

\subsection{Relevant/Interesting characteristics}
\begin{itemize}
    \item Concurrency
    \item Cron spec support
\end{itemize}

\subsection{Executors}

\subsection{Metrics}
\subsection{Processors}
\subsection{Job Retries}
\subsection{Embedded Storage}
\subsection{Target nodes spec}
\subsection{Clustering}
\label{clustering}






% todo: make this a paragraph instead ???
\subsection{No Single Point of Failure}
This no SPOF characteristic is very relevant for systems that depend on workload automation to function i.e. the scheduler dependee
system might be fault-tolerant, but the scheduler itself might not, making these "fault-tolerant" systems, indirectly, not as
so - Dkron fixes this problem by, as they claim, being the only existing scheduler with no SPOF. % ! REPETITIVE TEXT

% ? Acceptable Performance --> we'll find out on tests
Therefore, with acceptable performance, whilst providing Reliability? and Availability?, Dkron is an interesting solution
for use-cases that must guarantee fault-tolerance.

\section{Experimental Design}
DESCRIPTION AND JUSTIFICATION OF THE EXPERIMENTAL DESIGN

After analysing Dkron's design and particularities, the Experimental Design was initiated with the
goal to extrapolate the most possible information out of the decisions that will be discussed below.

A Fractional Factorial Design was used in order to use more factors (minimum of 6), whilst reducing
the amount of experiments required to be done.

A $2^{k-p}$ was used with \textit{k=6} and \textit{p=3} combined factors, resulting
in a total of 8 experiments. Below is the signed table FIGX and respective resulting effects FIXG.

\begin{figure}
\centering
\includegraphics[width=0.25\textwidth]{media/dkron-logo.png}
%\caption{dkron Logo .} \label{fig1}
\end{figure}

\begin{figure}
\centering
\includegraphics[width=0.25\textwidth]{media/dkron-logo.png}
%\caption{dkron Logo .} \label{fig1}
\end{figure}

\subsection{Factors}
As can be observed, the factors are the following:
\begin{itemize}
    \item HasOnDemandJobs
    \item CPU Limit (m)
    \item Memory Limit (GiB)
    \item Dkron Servers
    \item Dkron Agents
    \item Concurrent
\end{itemize}

Regarding the rationale for the choice of each factor. When deciding for factors,
after analysing the particularities of Dkron, some questions were raised:
\begin{enumerate}
    \item
\end{enumerate}

The conclusions from the analysis and consequently, the attempt to answer the above questions
can be found in subsection \ref{results}

\par \textbf{HasOnDemandJobs:} Dkron is mainly built to schedule recurring jobs,
and [this github](https://github.com/distribworks/dkron/issues/578) issue confirms that it was not initially planned to support immediately,
one time, executed jobs. The main exploratory idea was to analyse how immediate jobs are reacted to
i.e. if they have some threshold to be accepted in case all the pods are busy, or if in the case
all the pods are busy, the request is simply rejected.
\par \textbf{CPU Limit (m):} Dkron uses Raft to achieve consensus between the Dkron Agents.
Distributed consensus protocols usually are expected to be CPU and Memory bound therefore,
this factor is relevant to observe the impact of the Dkron Servers realizing consensus and
providing reliability.
\par \textbf{Memory Limit (GiB):} Likewise, due to the actions of state management and replication
being heavily required and frequent in these kinds of protocols, Memory also seemed a relevant
factor to take into account.
\par \textbf{Dkron Agents:} A Dkron Agent has a very simple goal, to execute jobs dispatched by
Dkron Servers. Having this simple pod that does not participate on consensus and only executes jobs
seemed to be the clear factor to increase for performance gains.
\par \textbf{Dkron Servers:} Dkron Servers do what Dkron Agents do plus scheduling of jobs,
handling data storage and participating on leader election. Since these 2 present very
distinguishable characteristics, it seemed relevant to analyse their interaction.
\par \textbf{Concurrent:} Dkron is states that if no Dkron Agent/Server is available

Dkron Agents in particular was a factor that unfortunately could not be configured in the
desired way to extrapolate clear conclusions and answer the initial questions.


MEMORY LIMIT NOTES: although no memory heavy jobs are done, memory usage was very high (raft?)

\subsection{Factor Levels}
Acknowledging there is the method of $2^k$ Factorial Design, it would be interesting to
try with some minimum and maximum values to look for \textit{unidirectional effects} and
in case the factor is has a unidirectional effect decide on the values from there. However,
from deploying an Azure Kubernetes Service to Dkron becoming ready was taking approximately
10 minutes and doing a Rolling Update was proving to be challenging, from the non-clear dkron's
helm chart to the particular mechanism of Dkron's clustering (\ref{clustering}).

Considering those challenges and the limited time, the approach to find the levels was heuristics:
\begin{itemize}
    \item For computational resources, i.e., CPU Limit and Memory Limit, an optimal point between
    these resources and prices was the consideration.
    \item For the ratio between Dkron Agents and Dkron Servers, an initial goal was set, until
    challenges were found, making it unable to use the desired levels, servers (3 to 5) and agents (0 to 3).
    Below an oversimplification of the challenge will be shared.
    \item For the benchmark workload parameters, these are simply binary values.
\end{itemize}

As for the challenge with setting the desired Dkron Agents replicas, it seems dkron helm chart
is still neither stable, nor prioritized by Dkron's team, an unfortunate late discovery
as it was unfeasible to leave the already too invested kubernetes and helm deployment leaving.
the only option to analyse with Dkron Agent as more of a binary value, 0 or 1.
Particularly, the issues seems to be with one of the templates \textit{agent-deployment.yaml} or
\textit{agent-hpa} which is ignoring the agent's set replica count and only creates 1,
independently of the set value, 0 or 100.

\subsection{Confounded Factors}
Confounding is used to reduce the number of ran experiments while being able to use a broader range
of factors. It is relevant to note that reducing the number of experiments in favor of time and cost savings
and sole increase in factors is not the best approach. Instead, it should be given preference to confound
factors while maintaining a higher level of experiments where their experiment error can be considered
in the effect results.

When confounding factors we should confound 1) factors where the interaction is probable to be negligible,
2) factors where combined effects are not so relevant to the analyis.

\begin{itemize}
    \item \textbf{HasOnDemandJobs + CPU Limit for Dkron Servers:} these 2 confounded factors are unlikely to interact since the expected jobs done by
        a scheduler are not heavy, and sometimes of workflow continuation or triggering.
        Both of these confounded factors would interact more if confounded with, e.g., Dkron Servers,
        for reasons of consensus overhead already explored.
    \item textbf{HasOnDemandJobs and Memory confounded for Dkron Agents:} same rationale as
    HasOnDemandJobs + CPU Limit.
    \item textbf{CPU Limit and Memory Limit for Concurrency}: same rationale as HasOnDemandJobs
    + CPU Limit.
\end{itemize}


\section{Results}
\label{results}
\section{Conclusion}

\subsection{Limitations}
Dkron's helm chart is still not stable for an easy deployment. Documentation is lacking, and
it seems there is no stable helm chart for dkron. Additionally, during bug fixing and deployment
problem resolving, I was left with the idea that [a lot more other developers face their own
unexpected issues with dkron's helm chart](https://github.com/distribworks/dkron/issues?q=helm).


% ! %%%
% ! %%% EXAMPLES BELOW
% ! %%%

\begin{table}
\caption{Table captions should be placed above the
tables.}\label{tab1}
\begin{tabular}{|l|l|l|}
\hline
Heading level &  Example & Font size and style\\
\hline
Title (centered) &  {\Large\bfseries Lecture Notes} & 14 point, bold\\
1st-level heading &  {\large\bfseries 1 Introduction} & 12 point, bold\\
2nd-level heading & {\bfseries 2.1 Printing Area} & 10 point, bold\\
3rd-level heading & {\bfseries Run-in Heading in Bold.} Text follows & 10 point, bold\\
4th-level heading & {\itshape Lowest Level Heading.} Text follows & 10 point, italic\\
\hline
\end{tabular}
\end{table}


\noindent Displayed equations are centered and set on a separate
line.
\begin{equation}
x + y = z
\end{equation}
Please try to avoid rasterized images for line-art diagrams and
schemas. Whenever possible, use vector graphics instead (see
%Fig.~\ref{fig1}).

\begin{figure}
\includegraphics[width=\textwidth]{fig1.eps}
\caption{A figure caption is always placed below the illustration.
Please note that short captions are centered, while long ones are
justified by the macro package automatically.} \label{fig1}
\end{figure}

\begin{theorem}
This is a sample theorem. The run-in heading is set in bold, while
the following text appears in italics. Definitions, lemmas,
propositions, and corollaries are styled the same way.
\end{theorem}
%
% the environments 'definition', 'lemma', 'proposition', 'corollary',
% 'remark', and 'example' are defined in the LLNCS documentclass as well.
%
\begin{proof}
Proofs, examples, and remarks have the initial word in italics,
while the following text appears in normal font.
\end{proof}
For citations of references, we prefer the use of square brackets
and consecutive numbers. Citations using labels or the author/year
convention are also acceptable. The following bibliography provides
a sample reference list with entries for journal
articles~\cite{ref_article1}, an LNCS chapter~\cite{ref_lncs1}, a
book~\cite{ref_book1}, proceedings without editors~\cite{ref_proc1},
and a homepage~\cite{ref_url1}. Multiple citations are grouped
\cite{ref_article1,ref_lncs1,ref_book1},
\cite{ref_article1,ref_book1,ref_proc1,ref_url1}.

\begin{credits}
\subsubsection{\ackname} A bold run-in heading in small font size at the end of the paper is
used for general acknowledgments, for example: This study was funded
by X (grant number Y).

\subsubsection{\discintname}
It is now necessary to declare any competing interests or to specifically
state that the authors have no competing interests. Please place the
statement with a bold run-in heading in small font size beneath the
(optional) acknowledgments\footnote{If EquinOCS, our proceedings submission
system, is used, then the disclaimer can be provided directly in the system.},
for example: The authors have no competing interests to declare that are
relevant to the content of this article. Or: Author A has received research
grants from Company W. Author B has received a speaker honorarium from
Company X and owns stock in Company Y. Author C is a member of committee Z.
\end{credits}
%
% ---- Bibliography ----
%
% BibTeX users should specify bibliography style 'splncs04'.
% References will then be sorted and formatted in the correct style.
%
% \bibliographystyle{splncs04}
% \bibliography{mybibliography}
%
\begin{thebibliography}{8}
\bibitem{ref_article1}
Author, F.: Article title. Journal \textbf{2}(5), 99--110 (2016)

\bibitem{ref_lncs1}
Author, F., Author, S.: Title of a proceedings paper. In: Editor,
F., Editor, S. (eds.) CONFERENCE 2016, LNCS, vol. 9999, pp. 1--13.
Springer, Heidelberg (2016). \doi{10.10007/1234567890}

\bibitem{ref_book1}
Author, F., Author, S., Author, T.: Book title. 2nd edn. Publisher,
Location (1999)

\bibitem{ref_proc1}
Author, A.-B.: Contribution title. In: 9th International Proceedings
on Proceedings, pp. 1--2. Publisher, Location (2010)

\bibitem{ref_url1}
LNCS Homepage, \url{http://www.springer.com/lncs}, last accessed 2023/10/25
\end{thebibliography}
\end{document}
